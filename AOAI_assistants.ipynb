{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Assistants using the Python OpenAI SDK\n",
    "\n",
    "In this demo, we'll use Azure OpenAI assistants (preview) through the Python OpenAI SDK to automatically generate a TPS report for a fictional company called Contoso. Our AI assistant will help us produce a plot from our data, analyze the plot, and then summarize everything in a report with coversheet included!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistants concepts\n",
    "\n",
    "Azure OpenAI Assistants allows you to create AI assistants tailored to your needs through custom instructions and augmented by advanced tools like code interpreter, and custom functions.\n",
    "\n",
    "- **Assistants**: encapsulates the model, its instructions, tools, and context\n",
    "- **Threads**: represents the state of a conversation\n",
    "- **Runs**: executes an Assistant on a Thread, and includes textual responses and multi-step tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai azure-identity pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the client\n",
    "\n",
    "We'll configure the AzureOpenAI client and authenticate using Microsoft Entra ID (formerly Azure Active Directory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "    api_version=\"2024-03-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a plot from our data\n",
    "\n",
    "We have csv data that contains the average latency for several resources over a 24 hour period. Let's read the data with pandas and then create a file to use with future requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Resource A</th>\n",
       "      <th>Resource B</th>\n",
       "      <th>Resource C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>0:00</td>\n",
       "      <td>76</td>\n",
       "      <td>150</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>1:00</td>\n",
       "      <td>349</td>\n",
       "      <td>209</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>2:00</td>\n",
       "      <td>410</td>\n",
       "      <td>314</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Time  Resource A  Resource B  Resource C\n",
       "0  3/25/2024  0:00          76         150         123\n",
       "1  3/25/2024  1:00         349         209         115\n",
       "2  3/25/2024  2:00         410         314         110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency_data = pd.read_csv(\"data/contoso_data.csv\")\n",
    "latency_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open('data/contoso_data.csv',\"rb\"),\n",
    "  purpose='assistants',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by creating an Assistant. This call will capture the instructions for the assistant, which tools are available to use, and the model to use. In our case, we'll equip our assistant with the code interpreter tool which allows the Assistant to write and run Python code in a sandboxed execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data scientist assistant. When given data and a query, \\\n",
    "    write the necessary code to create the proper visualization.\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose message and run thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a thread and add our message context for the assistant. We'll include our data file ID in the message since the assistant will need the file to complete the task. Now we can run the thread and wait for a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Visualize Latency over Time as a line plot across Resources, where the colors of the lines are red (Resource A), green (Resource B), and blue (Resource C). Title the plot 'Avg Latency (last 24 hrs)'. The plot should fit on single sheet of paper.\",\n",
    "        \"file_ids\": [file.id]\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a helper function, `wait_until_done` to help us ping the service for updates on the thread until it's done. We can see the \"thought process\" of the assistant with each update as it's working on our request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_until_done(run):\n",
    "    client.beta.threads.runs.poll(\n",
    "        run_id=run.id,\n",
    "        thread_id=thread.id,\n",
    "    )\n",
    "\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    latest_message = messages.data[0].content[0]\n",
    "    for message in messages.data[::-1]:\n",
    "        print(f\"Assistant update: {message.content}\")\n",
    "\n",
    "    if latest_message.type == \"image_file\":\n",
    "        print(\"Image has been created!\")\n",
    "        return latest_message\n",
    "    elif latest_message.type == \"text\" and \\\n",
    "        latest_message.text.annotations and \\\n",
    "            latest_message.text.annotations[0].file_path.file_id:\n",
    "        print(\"File has been created!\")\n",
    "        return latest_message\n",
    "\n",
    "    print(f\"Something went wrong: {latest_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant update: MessageContentText(text=Text(annotations=[], value=\"Visualize Latency over Time as a line plot across Resources, where the colors of the lines are red (Resource A), green (Resource B), and blue (Resource C). Title the plot 'Avg Latency (last 24 hrs)'. The plot should fit on single sheet of paper.\"), type='text')\n",
      "Assistant update: MessageContentText(text=Text(annotations=[], value='The data has been successfully loaded and we have columns for \"Date\", \"Time\", and latency values for \"Resource A\", \"Resource B\", and \"Resource C\". The next step is to convert the \"Date\" and \"Time\" columns into a single datetime column so we can plot the data over time and then visualize the data as requested.'), type='text')\n",
      "Assistant update: MessageContentImageFile(image_file=ImageFile(file_id='assistant-A0sGEp2iHyowNQuEVXcFnhf4'), type='image_file')\n",
      "Image has been created!\n"
     ]
    }
   ],
   "source": [
    "message = wait_until_done(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the plot created and create a file for the assistant to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_id = message.image_file.file_id\n",
    "line_plot_path = \"./images/line_plot.png\"\n",
    "data = client.files.content(plot_file_id)\n",
    "with open(line_plot_path, \"wb\") as file:\n",
    "    file.write(data.read())\n",
    "\n",
    "plot_file = client.files.create(\n",
    "  file=open(line_plot_path, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![line_plot](images/line_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get insights from our line plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we created a data scientist assistant, let's ask it to provide insights from the plot we created in bullet point form so we can add it to our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_nNo6AiZ2lOGVOWWgdnZrFauY', assistant_id='asst_icp57fTulqSHekKqyURZksbV', cancelled_at=None, completed_at=None, created_at=1712019268, expires_at=1712019868, failed_at=None, file_ids=[], instructions='You are a data scientist assistant. When given data and a query,     write the necessary code to create the proper visualization.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_3rVT44Lmx0SHKiK4nqx0V7CR', tools=[ToolAssistantToolsCode(type='code_interpreter')], usage=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Provide the most important insights from the plot you just created in bullet point form. Call out any anomalies or trends you see.\"\n",
    "\n",
    ")\n",
    "\n",
    "client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate a cover sheet for our TPS Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all TPS reports require a coversheet, let's use AI to do that for us! Here we'll use DALL-E to generate an image for our coversheet and then create the file so the assistant can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "response = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"Create an image that encompasses the term 'latency'\",\n",
    ")\n",
    "cover_sheet_url = response.data[0].url\n",
    "response = httpx.get(cover_sheet_url)\n",
    "\n",
    "cover_sheet_path = './images/cover_sheet.png'\n",
    "\n",
    "\n",
    "with open(cover_sheet_path, 'wb') as file:\n",
    "  file.write(response.content)\n",
    "\n",
    "\n",
    "cover_sheet = client.files.create(\n",
    "  file=open(cover_sheet_path, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![coversheet.png](images/cover_sheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combine our plot, insights, and coversheet to a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine our plot, insights, and coversheet into a PDF file for our TPS report. We'll give the assistant explicit instructions on how to create the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Create a PDF file TPS report for the company Contoso. IMPORTANT: \\n\\nFIRST PAGE: include title 'Contoso TPS Report' centered at the top. Underneath text, include the image file included in this message. Crop or reduce size of image to make sure it fits on the page.\\n\\nSECOND PAGE: include the plot image included in this message. Underneath the plot, include the bullet point insights that were generated from the data. Both the plot and insights MUST fit on the page, reducing size, or wrapping any text to the next line, if necessary. Output these TWO PAGES as a .pdf file. Make sure the output is two pages, with each page matching the instructions from this message.\",\n",
    "    file_ids=[cover_sheet.id, plot_file.id]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant update: MessageContentText(text=Text(annotations=[], value=\"Create a PDF file TPS report for the company Contoso. IMPORTANT: \\n\\nFIRST PAGE: include title 'Contoso TPS Report' centered at the top. Underneath text, include the image file included in this message. Crop or reduce size of image to make sure it fits on the page.\\n\\nSECOND PAGE: include the plot image included in this message. Underneath the plot, include the bullet point insights that were generated from the data. Both the plot and insights MUST fit on the page, reducing size, or wrapping any text to the next line, if necessary. Output these TWO PAGES as a .pdf file. Make sure the output is two pages, with each page matching the instructions from this message.\"), type='text')\n",
      "Assistant update: MessageContentText(text=Text(annotations=[], value=\"It appears that there is an issue with saving one of the images in JPEG format because it's in 'RGBA' mode, which includes an alpha channel (transparency). JPEG does not support transparency, so we need to convert the image to 'RGB' mode before saving it as JPEG. I will fix this issue and proceed with the creation of the PDF.\"), type='text')\n",
      "Assistant update: MessageContentText(text=Text(annotations=[], value=\"There was a mistake in my usage of the `cell` function from the `fpdf` library. I passed incorrect keyword arguments that are not valid for the `cell` function. I need to correct the code to ensure the proper creation of the cell in the PDF document. Let's fix that and attempt to generate the PDF again.\"), type='text')\n",
      "Assistant update: MessageContentText(text=Text(annotations=[], value='It seems that the variable `insight_text` was lost when the previous cell failed to complete. Let me re-define the insights text and then complete the PDF generation process.'), type='text')\n",
      "Assistant update: MessageContentText(text=Text(annotations=[TextAnnotationFilePath(end_index=433, file_path=TextAnnotationFilePathFilePath(file_id='assistant-9oZtKynQTi0d6rQWnfykn9JS'), start_index=393, text='sandbox:/mnt/data/contoso_tps_report.pdf', type='file_path')], value='The PDF TPS report for the company Contoso has been successfully created. The report contains two pages, with the first page including the title \"Contoso TPS Report\" and the provided image, and the second page including the plot image along with the bullet point insights generated from the data.\\n\\nYou can download the PDF report using the following link:\\n\\n[Contoso TPS Report - Download PDF](sandbox:/mnt/data/contoso_tps_report.pdf)'), type='text')\n",
      "File has been created!\n"
     ]
    }
   ],
   "source": [
    "message = wait_until_done(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_id = message.text.annotations[0].file_path.file_id\n",
    "pdf_path = \"./report/tps_report.pdf\"\n",
    "\n",
    "data = client.files.content(pdf_file_id) \n",
    "with open(pdf_path, \"wb\") as file:\n",
    "    file.write(data.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "And we're done! In this short demo, we used Azure OpenAI Assistants through the Python OpenAI SDK to generate a fictional TPS report for us. The Assistant plotted our data, analyzed the plot, generated a coversheet, and combined everything into a PDF report for us to download. See [report/tps_report.pdf](report/tps_report.pdf) for the final report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Assistants using the Python OpenAI SDK\n",
    "\n",
    "In this demo, we'll use Azure OpenAI assistants (preview) through the Python OpenAI SDK to automatically generate a TPS report for a fictional company called Contoso. We'll create an AI assistant to help us produce a plot from our data, gather insights from the plot, and then summarize everything in a report with coversheet included!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistants concepts\n",
    "\n",
    "Azure OpenAI Assistants allows you to create AI assistants tailored to your needs through custom instructions and augmented by advanced tools like code interpreter, and custom functions.\n",
    "\n",
    "- **Assistants**: encapsulates the model, its instructions, tools, and (context) documents\n",
    "- **Threads**: represents the state of a conversation\n",
    "- **Runs**: executes an Assistant on a Thread, including the textual responses and multi-step tool use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai azure-identity pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the client\n",
    "\n",
    "We'll configure the AzureOpenAI client and authenticate using Microsoft Entra ID (formerly Azure Active Directory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "    api_version=\"2024-03-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a plot from our data\n",
    "\n",
    "We have csv data that contains an average latency for each resource over a 24 hour period. We'll start by reading the file with pandas and then creating a file so that assistants can use it with future requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Resource A</th>\n",
       "      <th>Resource B</th>\n",
       "      <th>Resource C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>0:00</td>\n",
       "      <td>76</td>\n",
       "      <td>150</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>1:00</td>\n",
       "      <td>349</td>\n",
       "      <td>209</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/25/2024</td>\n",
       "      <td>2:00</td>\n",
       "      <td>410</td>\n",
       "      <td>314</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Time  Resource A  Resource B  Resource C\n",
       "0  3/25/2024  0:00          76         150         123\n",
       "1  3/25/2024  1:00         349         209         115\n",
       "2  3/25/2024  2:00         410         314         110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latency_data = pd.read_csv(\"data/contoso_data.csv\")\n",
    "latency_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open('data/contoso_data.csv',\"rb\"),\n",
    "  purpose='assistants',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by creating an Assistant. This call will capture the instructions for the assistant, which tools are available to use, and model to use. In our case, we'll equip our assistant with the code interpreter tool which allows the Assistants API to write and run Python code in a sandboxed execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a data scientist assistant. When given data and a query, \\\n",
    "    write the necessary code to create the proper visualization.\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose message and run thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a thread and add our message context for the assistant. We'll include the data file ID in the message since the assistant will need the file to complete the task. Now we can run the thread and wait for a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Visualize Latency over Time as a line plot across Resources, where the colors of the lines are red (Resource A), green (Resource B), and blue (Resource C). Title the plot 'Avg Latency (last 24 hrs)'. The plot should fit on single sheet of paper.\",\n",
    "        \"file_ids\": [file.id]\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll add a helper function, `wait_until_done` to help us ping the service for updates on the thread until it's done. We can see the \"thought process\" of the assistant with each update as it's working on our request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_until_done(run):\n",
    "    status = \"\"\n",
    "    while status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        status = run.status\n",
    "\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        latest_message = messages.data[0].content[0]\n",
    "        print(f\"Assistant update: {latest_message.text.value}\")\n",
    "        time.sleep(10)\n",
    "\n",
    "    if latest_message.type == \"image_file\":\n",
    "        print(\"Image has been created!\")\n",
    "        return latest_message\n",
    "    elif latest_message.type == \"text\" and \\\n",
    "        latest_message.text.annotations and \\\n",
    "            latest_message.text.annotations[0].file_path.file_id:\n",
    "        print(\"File has been created!\")\n",
    "        return latest_message\n",
    "\n",
    "    print(f\"Something went wrong: {latest_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant update: Visualize Latency over Time as a line plot across Resources, where the colors of the lines are red (Resource A), green (Resource B), and blue (Resource C). Title the plot 'Avg Latency (last 24 hrs)'. The plot should fit on single sheet of paper.\n",
      "Image has been created!\n"
     ]
    }
   ],
   "source": [
    "message = wait_until_done(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll view the plot created and create a file for the assistant to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_id = message.image_file.file_id\n",
    "line_plot_path = \"./images/line_plot3.png\"\n",
    "data = client.files.content(plot_file_id)\n",
    "with open(line_plot_path, \"wb\") as file:\n",
    "    file.write(data.read())\n",
    "\n",
    "plot_file = client.files.create(\n",
    "  file=open(line_plot_path, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![line_plot](images/line_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get insights from our line plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we created a data scientist assistant, let's ask it to provide insights from the plot we created in bullet point form so we can add it to our report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_amLSh3IwrN7wCTyvSb0k6EOe', assistant_id='asst_DJuwVZh8InhiuUn77gwyHPC6', cancelled_at=None, completed_at=None, created_at=1711751454, expires_at=1711752054, failed_at=None, file_ids=[], instructions='You are a data scientist assistant. When given data and a query,     write the necessary code to create the proper visualization.', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_E76FwIRZ41HdN5qgpDJOVyRg', tools=[ToolAssistantToolsCode(type='code_interpreter')], usage=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Provide the most important insights from the plot you just created in bullet point form. Call out any anomalies or trends you see.\"\n",
    "\n",
    ")\n",
    "\n",
    "client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate a cover sheet for our TPS Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all TPS reports require a coversheet, let's use AI to do that for us! Here we'll use DALL-E to generate an image for our coversheet and then create the file so the assistant can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "response = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt=\"Create an image that encompasses the term 'latency'\",\n",
    ")\n",
    "cover_sheet_url = response.data[0].url\n",
    "response = httpx.get(cover_sheet_url)\n",
    "\n",
    "cover_sheet_path = './images/cover_sheet.png'\n",
    "\n",
    "\n",
    "with open(cover_sheet_path, 'wb') as file:\n",
    "  file.write(response.content)\n",
    "\n",
    "\n",
    "cover_sheet = client.files.create(\n",
    "  file=open(cover_sheet_path, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![coversheet.png](images/cover_sheet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combine our plot, insights, and coversheet to a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine our plot, insights, and coversheet into a PDF file for our TPS report. We'll give the assistant explicit instructions on how to create the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Create a PDF file TPS report for the company Contoso. IMPORTANT: \\n\\nFIRST PAGE: include title 'Contoso TPS Report' centered at the top. Underneath text, include the image file included in this message. Crop or reduce size of image to make sure it fits on the page.\\n\\nSECOND PAGE: include the plot image included in this message. Underneath the plot, include the bullet point insights that were generated from the data. Both the plot and insights MUST fit on the page, reducing size, or wrapping any text to the next line, if necessary. Output these TWO PAGES as a .pdf file. Make sure the output is two pages, with each page matching the instructions from this message.\",\n",
    "    file_ids=[cover_sheet.id, plot_file.id]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant update: The TPS report for Contoso has been successfully created as a two-page PDF document. The first page includes the title and the first image, and the second page contains the plot image and the insights listed in bullet points. \n",
      "\n",
      "You can download the report from the following link:\n",
      "\n",
      "[Download Contoso TPS Report PDF](sandbox:/mnt/data/Contoso_TPS_Report.pdf)\n",
      "File has been created!\n"
     ]
    }
   ],
   "source": [
    "message = wait_until_done(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_id = message.text.annotations[0].file_path.file_id\n",
    "pdf_path = \"./report/tps_report.pdf\"\n",
    "\n",
    "data = client.files.content(pdf_file_id) \n",
    "with open(pdf_path, \"wb\") as file:\n",
    "    file.write(data.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! See [report/tps_report.pdf](report/tps_report.pdf) for the final report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
